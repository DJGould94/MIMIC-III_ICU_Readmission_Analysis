{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_root_path = \"/tmp/mimic3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "\n",
    "def is_subject_folder(x):\n",
    "    return str.isdigit(x)\n",
    "\n",
    "\n",
    "def main(subjects_root_path):\n",
    "\n",
    "    n_events = 0                   # total number of events\n",
    "    empty_hadm = 0                 # HADM_ID is empty in events.csv. We exclude such events.\n",
    "    no_hadm_in_stay = 0            # HADM_ID does not appear in stays.csv. We exclude such events.\n",
    "    no_icustay = 0                 # ICUSTAY_ID is empty in events.csv. We try to fix such events.\n",
    "    recovered = 0                  # empty ICUSTAY_IDs are recovered according to stays.csv files (given HADM_ID)\n",
    "    could_not_recover = 0          # empty ICUSTAY_IDs that are not recovered. This should be zero.\n",
    "    icustay_missing_in_stays = 0   # ICUSTAY_ID does not appear in stays.csv. We exclude such events.\n",
    "\n",
    "    subdirectories = os.listdir(subjects_root_path)\n",
    "    subjects = list(filter(is_subject_folder, subdirectories))\n",
    "\n",
    "    for (index, subject) in enumerate(subjects):\n",
    "        if index % 100 == 0:\n",
    "            print(\"processed {} / {} {}\\r\".format(index+1, len(subjects), ' '*10))\n",
    "\n",
    "        stays_df = pd.read_csv(os.path.join(subjects_root_path, subject, 'stays.csv'), index_col=False,\n",
    "                               dtype={'HADM_ID': str, \"ICUSTAY_ID\": str})\n",
    "        stays_df.columns = stays_df.columns.str.upper()\n",
    "\n",
    "        # assert that there is no row with empty ICUSTAY_ID or HADM_ID\n",
    "        assert(not stays_df['ICUSTAY_ID'].isnull().any())\n",
    "        assert(not stays_df['HADM_ID'].isnull().any())\n",
    "\n",
    "        # assert there are no repetitions of ICUSTAY_ID or HADM_ID\n",
    "        # since admissions with multiple ICU stays were excluded\n",
    "        assert(len(stays_df['ICUSTAY_ID'].unique()) == len(stays_df['ICUSTAY_ID']))\n",
    "        #assert(len(stays_df['HADM_ID'].unique()) == len(stays_df['HADM_ID']))\n",
    "        if os.path.isfile(os.path.join(subjects_root_path, subject, 'events.csv'))==False:\n",
    "            continue\n",
    "        events_df = pd.read_csv(os.path.join(subjects_root_path, subject, 'events.csv'), index_col=False,\n",
    "                                dtype={'HADM_ID': str, \"ICUSTAY_ID\": str})\n",
    "        events_df.columns = events_df.columns.str.upper()\n",
    "        n_events += events_df.shape[0]\n",
    "\n",
    "        # we drop all events for them HADM_ID is empty\n",
    "        # TODO: maybe we can recover HADM_ID by looking at ICUSTAY_ID\n",
    "        empty_hadm += events_df['HADM_ID'].isnull().sum()\n",
    "        events_df = events_df.dropna(subset=['HADM_ID'])\n",
    "\n",
    "        merged_df = events_df.merge(stays_df, left_on=['HADM_ID'], right_on=['HADM_ID'],\n",
    "                                    how='left', suffixes=['', '_r'], indicator=True)\n",
    "\n",
    "        # we drop all events for which HADM_ID is not listed in stays.csv\n",
    "        # since there is no way to know the targets of that stay (for example mortality)\n",
    "        no_hadm_in_stay += (merged_df['_merge'] == 'left_only').sum()\n",
    "        merged_df = merged_df[merged_df['_merge'] == 'both']\n",
    "\n",
    "        # if ICUSTAY_ID is empty in stays.csv, we try to recover it\n",
    "        # we exclude all events for which we could not recover ICUSTAY_ID\n",
    "        cur_no_icustay = merged_df['ICUSTAY_ID'].isnull().sum()\n",
    "        no_icustay += cur_no_icustay\n",
    "        merged_df.loc[:, 'ICUSTAY_ID'] = merged_df['ICUSTAY_ID'].fillna(merged_df['ICUSTAY_ID_r'])\n",
    "        recovered += cur_no_icustay - merged_df['ICUSTAY_ID'].isnull().sum()\n",
    "        could_not_recover += merged_df['ICUSTAY_ID'].isnull().sum()\n",
    "        merged_df = merged_df.dropna(subset=['ICUSTAY_ID'])\n",
    "\n",
    "        # now we take a look at the case when ICUSTAY_ID is present in events.csv, but not in stays.csv\n",
    "        # this mean that ICUSTAY_ID in events.csv is not the same as that of stays.csv for the same HADM_ID\n",
    "        # we drop all such events\n",
    "        icustay_missing_in_stays += (merged_df['ICUSTAY_ID'] != merged_df['ICUSTAY_ID_r']).sum()\n",
    "        merged_df = merged_df[(merged_df['ICUSTAY_ID'] == merged_df['ICUSTAY_ID_r'])]\n",
    "\n",
    "        to_write = merged_df[['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'CHARTTIME', 'ITEMID', 'VALUE', 'VALUEUOM']]\n",
    "        to_write.to_csv(os.path.join(subjects_root_path, subject, 'events.csv'), index=False)\n",
    "\n",
    "    assert(could_not_recover == 0)\n",
    "    print('n_events: {}'.format(n_events))\n",
    "    print('empty_hadm: {}'.format(empty_hadm))\n",
    "    print('no_hadm_in_stay: {}'.format(no_hadm_in_stay))\n",
    "    print('no_icustay: {}'.format(no_icustay))\n",
    "    print('recovered: {}'.format(recovered))\n",
    "    print('could_not_recover: {}'.format(could_not_recover))\n",
    "    print('icustay_missing_in_stays: {}'.format(icustay_missing_in_stays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(subjects_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
